07-16 02:33:55.763 23350 23350 D SODBenchmark: Run 1: Inference time = 25 ms
07-16 02:33:55.989 23350 23350 D SODBenchmark: Run 2: Inference time = 16 ms
07-16 02:33:56.097 23350 23350 D SODBenchmark: Run 3: Inference time = 17 ms
07-16 02:33:56.204 23350 23350 D SODBenchmark: Run 4: Inference time = 16 ms
07-16 02:33:56.312 23350 23350 D SODBenchmark: Run 5: Inference time = 16 ms
07-16 02:33:56.418 23350 23350 D SODBenchmark: Run 6: Inference time = 16 ms
07-16 02:33:56.529 23350 23350 D SODBenchmark: Run 7: Inference time = 17 ms
07-16 02:33:56.637 23350 23350 D SODBenchmark: Run 8: Inference time = 15 ms
07-16 02:33:56.745 23350 23350 D SODBenchmark: Run 9: Inference time = 16 ms
07-16 02:33:56.853 23350 23350 D SODBenchmark: Run 10: Inference time = 16 ms
07-16 02:33:56.960 23350 23350 D SODBenchmark: Run 11: Inference time = 16 ms
07-16 02:33:57.066 23350 23350 D SODBenchmark: Run 12: Inference time = 16 ms
07-16 02:33:57.174 23350 23350 D SODBenchmark: Run 13: Inference time = 15 ms
07-16 02:33:57.280 23350 23350 D SODBenchmark: Run 14: Inference time = 15 ms
07-16 02:33:57.386 23350 23350 D SODBenchmark: Run 15: Inference time = 15 ms
07-16 02:33:57.493 23350 23350 D SODBenchmark: Run 16: Inference time = 16 ms
07-16 02:33:57.599 23350 23350 D SODBenchmark: Run 17: Inference time = 16 ms
07-16 02:33:57.705 23350 23350 D SODBenchmark: Run 18: Inference time = 16 ms
07-16 02:33:57.812 23350 23350 D SODBenchmark: Run 19: Inference time = 16 ms
07-16 02:33:57.918 23350 23350 D SODBenchmark: Run 20: Inference time = 16 ms
07-16 02:33:58.024 23350 23350 D SODBenchmark: Run 21: Inference time = 15 ms
07-16 02:33:58.129 23350 23350 D SODBenchmark: Run 22: Inference time = 15 ms
07-16 02:33:58.236 23350 23350 D SODBenchmark: Run 23: Inference time = 16 ms
07-16 02:33:58.342 23350 23350 D SODBenchmark: Run 24: Inference time = 15 ms
07-16 02:33:58.448 23350 23350 D SODBenchmark: Run 25: Inference time = 15 ms
07-16 02:33:58.558 23350 23350 D SODBenchmark: Run 26: Inference time = 19 ms
07-16 02:33:58.664 23350 23350 D SODBenchmark: Run 27: Inference time = 15 ms
07-16 02:33:58.770 23350 23350 D SODBenchmark: Run 28: Inference time = 15 ms
07-16 02:33:58.876 23350 23350 D SODBenchmark: Run 29: Inference time = 15 ms
07-16 02:33:58.981 23350 23350 D SODBenchmark: Run 30: Inference time = 15 ms
07-16 02:33:59.088 23350 23350 D SODBenchmark: Run 31: Inference time = 16 ms
07-16 02:33:59.193 23350 23350 D SODBenchmark: Run 32: Inference time = 15 ms
07-16 02:33:59.300 23350 23350 D SODBenchmark: Run 33: Inference time = 16 ms
07-16 02:33:59.406 23350 23350 D SODBenchmark: Run 34: Inference time = 16 ms
07-16 02:33:59.512 23350 23350 D SODBenchmark: Run 35: Inference time = 16 ms
07-16 02:33:59.618 23350 23350 D SODBenchmark: Run 36: Inference time = 15 ms
07-16 02:33:59.724 23350 23350 D SODBenchmark: Run 37: Inference time = 15 ms
07-16 02:33:59.830 23350 23350 D SODBenchmark: Run 38: Inference time = 15 ms
07-16 02:33:59.936 23350 23350 D SODBenchmark: Run 39: Inference time = 15 ms
07-16 02:34:00.043 23350 23350 D SODBenchmark: Run 40: Inference time = 16 ms
07-16 02:34:00.205 23350 23350 D SODBenchmark: Run 41: Inference time = 24 ms
07-16 02:34:00.323 23350 23350 D SODBenchmark: Run 42: Inference time = 20 ms
07-16 02:34:00.436 23350 23350 D SODBenchmark: Run 43: Inference time = 15 ms
07-16 02:34:00.549 23350 23350 D SODBenchmark: Run 44: Inference time = 16 ms
07-16 02:34:00.663 23350 23350 D SODBenchmark: Run 45: Inference time = 16 ms
07-16 02:34:00.777 23350 23350 D SODBenchmark: Run 46: Inference time = 16 ms
07-16 02:34:00.890 23350 23350 D SODBenchmark: Run 47: Inference time = 16 ms
07-16 02:34:01.004 23350 23350 D SODBenchmark: Run 48: Inference time = 15 ms
07-16 02:34:01.117 23350 23350 D SODBenchmark: Run 49: Inference time = 15 ms
07-16 02:34:01.231 23350 23350 D SODBenchmark: Run 50: Inference time = 16 ms
07-16 02:34:01.344 23350 23350 D SODBenchmark: Run 51: Inference time = 16 ms
07-16 02:34:01.460 23350 23350 D SODBenchmark: Run 52: Inference time = 15 ms
07-16 02:34:01.569 23350 23350 D SODBenchmark: Run 53: Inference time = 16 ms
07-16 02:34:01.678 23350 23350 D SODBenchmark: Run 54: Inference time = 16 ms
07-16 02:34:01.793 23350 23350 D SODBenchmark: Run 55: Inference time = 15 ms
07-16 02:34:01.904 23350 23350 D SODBenchmark: Run 56: Inference time = 20 ms
07-16 02:34:02.024 23350 23350 D SODBenchmark: Run 57: Inference time = 25 ms
07-16 02:34:02.140 23350 23350 D SODBenchmark: Run 58: Inference time = 15 ms
07-16 02:34:02.254 23350 23350 D SODBenchmark: Run 59: Inference time = 16 ms
07-16 02:34:02.378 23350 23350 D SODBenchmark: Run 60: Inference time = 29 ms
07-16 02:34:02.492 23350 23350 D SODBenchmark: Run 61: Inference time = 15 ms
07-16 02:34:02.601 23350 23350 D SODBenchmark: Run 62: Inference time = 16 ms
07-16 02:34:02.735 23350 23350 D SODBenchmark: Run 63: Inference time = 23 ms
07-16 02:34:02.844 23350 23350 D SODBenchmark: Run 64: Inference time = 16 ms
07-16 02:34:02.983 23350 23350 D SODBenchmark: Run 65: Inference time = 40 ms
07-16 02:34:03.096 23350 23350 D SODBenchmark: Run 66: Inference time = 17 ms
07-16 02:34:03.213 23350 23350 D SODBenchmark: Run 67: Inference time = 19 ms
07-16 02:34:03.364 23350 23350 D SODBenchmark: Run 68: Inference time = 55 ms
07-16 02:34:03.475 23350 23350 D SODBenchmark: Run 69: Inference time = 15 ms
07-16 02:34:03.584 23350 23350 D SODBenchmark: Run 70: Inference time = 20 ms
07-16 02:34:03.703 23350 23350 D SODBenchmark: Run 71: Inference time = 16 ms
07-16 02:34:03.817 23350 23350 D SODBenchmark: Run 72: Inference time = 16 ms
07-16 02:34:03.938 23350 23350 D SODBenchmark: Run 73: Inference time = 24 ms
07-16 02:34:04.066 23350 23350 D SODBenchmark: Run 74: Inference time = 30 ms
07-16 02:34:04.173 23350 23350 D SODBenchmark: Run 75: Inference time = 16 ms
07-16 02:34:04.285 23350 23350 D SODBenchmark: Run 76: Inference time = 16 ms
07-16 02:34:04.395 23350 23350 D SODBenchmark: Run 77: Inference time = 15 ms
07-16 02:34:04.501 23350 23350 D SODBenchmark: Run 78: Inference time = 16 ms
07-16 02:34:04.621 23350 23350 D SODBenchmark: Run 79: Inference time = 26 ms
07-16 02:34:04.737 23350 23350 D SODBenchmark: Run 80: Inference time = 22 ms
07-16 02:34:04.846 23350 23350 D SODBenchmark: Run 81: Inference time = 19 ms
07-16 02:34:04.963 23350 23350 D SODBenchmark: Run 82: Inference time = 20 ms
07-16 02:34:05.082 23350 23350 D SODBenchmark: Run 83: Inference time = 16 ms
07-16 02:34:05.195 23350 23350 D SODBenchmark: Run 84: Inference time = 16 ms
07-16 02:34:05.309 23350 23350 D SODBenchmark: Run 85: Inference time = 17 ms
07-16 02:34:05.420 23350 23350 D SODBenchmark: Run 86: Inference time = 17 ms
07-16 02:34:05.533 23350 23350 D SODBenchmark: Run 87: Inference time = 16 ms
07-16 02:34:05.642 23350 23350 D SODBenchmark: Run 88: Inference time = 18 ms
07-16 02:34:05.754 23350 23350 D SODBenchmark: Run 89: Inference time = 18 ms
07-16 02:34:05.865 23350 23350 D SODBenchmark: Run 90: Inference time = 16 ms
07-16 02:34:05.972 23350 23350 D SODBenchmark: Run 91: Inference time = 16 ms
07-16 02:34:06.085 23350 23350 D SODBenchmark: Run 92: Inference time = 16 ms
07-16 02:34:06.197 23350 23350 D SODBenchmark: Run 93: Inference time = 16 ms
07-16 02:34:06.304 23350 23350 D SODBenchmark: Run 94: Inference time = 17 ms
07-16 02:34:06.420 23350 23350 D SODBenchmark: Run 95: Inference time = 16 ms
07-16 02:34:06.534 23350 23350 D SODBenchmark: Run 96: Inference time = 16 ms
07-16 02:34:06.641 23350 23350 D SODBenchmark: Run 97: Inference time = 18 ms
07-16 02:34:06.754 23350 23350 D SODBenchmark: Run 98: Inference time = 15 ms
07-16 02:34:06.871 23350 23350 D SODBenchmark: Run 99: Inference time = 16 ms
07-16 02:34:06.990 23350 23350 D SODBenchmark: Run 100: Inference time = 16 ms
07-16 02:34:06.990 23350 23350 D SODBenchmark: Average inference time over 100 runs: 17 ms


